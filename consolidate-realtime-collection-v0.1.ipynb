{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assemble daily method\n",
    "#from datetime import datetime\n",
    "#today = datetime.today()\n",
    "#date = datetime.strftime(today, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-16 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-16 Processing Complete. Process took 189.31341 seconds. \n",
      "\n",
      "2018-04-21 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-21 Processing Complete. Process took 185.967969 seconds. \n",
      "\n",
      "2018-04-22 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-22 Processing Complete. Process took 214.447921 seconds. \n",
      "\n",
      "2018-04-23 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-23 Processing Complete. Process took 232.366822 seconds. \n",
      "\n",
      "2018-04-24 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-24 Processing Complete. Process took 199.167027 seconds. \n",
      "\n",
      "2018-04-25 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-25 Processing Complete. Process took 181.856764 seconds. \n",
      "\n",
      "2018-04-26 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-26 Processing Complete. Process took 172.232064 seconds. \n",
      "\n",
      "2018-04-27 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-27 Processing Complete. Process took 189.510398 seconds. \n",
      "\n",
      "2018-04-28 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-28 Processing Complete. Process took 206.806883 seconds. \n",
      "\n",
      "2018-04-29 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-29 Processing Complete. Process took 201.734302 seconds. \n",
      "\n",
      "2018-04-30 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-04-30 Processing Complete. Process took 172.575386 seconds. \n",
      "\n",
      "2018-05-01 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n",
      "Generating .csv from consolidated dataframe...\n",
      "2018-05-01 Processing Complete. Process took 174.452246 seconds. \n",
      "\n",
      "2018-05-02 does not exists. Intializing processing...\n",
      "Retrieving all .json files within directory...\n",
      "Creating dataframe to consolidate all json files...\n"
     ]
    }
   ],
   "source": [
    "directory = \"/Users/chuamelia/Google Drive/Forecasting Time Series/citi-bike/ts-realtime-analysis-bike/event_logs/\"\n",
    "\n",
    "#Grab list of subdirectories\n",
    "subdirectories = [x[1] for x in os.walk(directory)]\n",
    "#Remove empty lists; we only want the subdirectories of event_logs\n",
    "subdirectories = [x for x in subdirectories if x != []][0]\n",
    "\n",
    "#Check if file has already been processed and creating list of unprocessed directories...\n",
    "process_directories = []\n",
    "for date in subdirectories:\n",
    "    if os.path.exists(\"/Users/chuamelia/Google Drive/Forecasting Time Series/citi-bike/ts-realtime-analysis-bike/event_csv/{0}.csv\".format(date))==False:\n",
    "        process_directories.append(date)\n",
    "\n",
    "for date in process_directories:\n",
    "    print(\"{0} does not exists. Intializing processing...\".format(date))\n",
    "    start = datetime.now()\n",
    "    path =\"/Users/chuamelia/Google Drive/Forecasting Time Series/citi-bike/ts-realtime-analysis-bike/event_logs/{0}/*.json\".format(date)\n",
    "    \n",
    "    print(\"Retrieving all .json files within directory...\")\n",
    "    all_json = glob.glob(path)\n",
    "    \n",
    "    print(\"Creating dataframe to consolidate all json files...\")\n",
    "    stationDF = pd.DataFrame()\n",
    "    _list = []\n",
    "    for json in all_json:\n",
    "        file = open(json,'r')\n",
    "        body = file.read()\n",
    "        data = ast.literal_eval(body)\n",
    "        stations = pd.DataFrame(data['data']['stations'])\n",
    "        stations[\"last_updated\"] = data[\"last_updated\"]\n",
    "        _list.append(stations)\n",
    "        file.close()\n",
    "    stationDF = pd.concat(_list)\n",
    "    \n",
    "    print(\"Generating .csv from consolidated dataframe...\")\n",
    "    event_csvPath = \"/Users/chuamelia/Google Drive/Forecasting Time Series/citi-bike/ts-realtime-analysis-bike/event_csv/{0}.csv\".format(date)\n",
    "    stationDF.to_csv(event_csvPath, sep=\",\",index=False)\n",
    "    end = datetime.now()\n",
    "    delta = (end-start)\n",
    "    delta = delta.total_seconds()\n",
    "    \n",
    "    print(\"{0} Processing Complete. Process took {1} seconds. \\n\".format(date, delta))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"{0} Processing Complete. Process took {1} seconds. \\n\".format(date, delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
